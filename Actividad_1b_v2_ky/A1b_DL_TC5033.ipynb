{"cells":[{"cell_type":"markdown","metadata":{"id":"-RwWN2Je92x_"},"source":["# TC 5033\n","## Deep Learning\n","## Fully Connected Deep Neural Networks\n","\n","#### Activity 1b: Implementing a Fully Connected Network for Kaggle ASL Dataset\n","\n","- Objective\n","\n","The aim of this part of the activity is to apply your understanding of Fully Connected Networks by implementing a multilayer network for the [Kaggle ASL (American Sign Language) dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet). While you have been provided with a complete solution for a Fully Connected Network using Numpy for the MNIST dataset, you are encouraged to try to come up with the solution.\n","\n","- Instructions\n","\n","    This activity requires submission in teams of 3 or 4 members. Submissions from smaller or larger teams will not be accepted unless prior approval has been granted (only due to exceptional circumstances). While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n","\n","    Load and Preprocess Data: You are provided a starter code to load the data. Be sure to understand the code.\n","\n","    Review MNIST Notebook (Optional): Before diving into this activity, you have the option to revisit the MNIST example to refresh your understanding of how to build a Fully Connected Network using Numpy.\n","\n","    Start Fresh: Although you can refer to the MNIST solution at any point, try to implement the network for the ASL dataset on your own. This will reinforce your learning and understanding of the architecture and mathematics involved.\n","\n","    Implement Forward and Backward Pass: Write the code to perform the forward and backward passes, keeping in mind the specific challenges and characteristics of the ASL dataset.\n","    \n","     Design the Network: Create the architecture of the Fully Connected Network tailored for the ASL dataset. Choose the number of hidden layers, neurons, and hyperparameters judiciously.\n","\n","    Train the Model: Execute the training loop, ensuring to track performance metrics such as loss and accuracy.\n","\n","    Analyze and Document: Use Markdown cells to document in detail the choices you made in terms of architecture and hyperparameters, you may use figures, equations, etc to aid in your explanations. Include any metrics that help justify these choices and discuss the model's performance.  \n","\n","- Evaluation Criteria\n","\n","    - Code Readability and Comments\n","    - Appropriateness of chosen architecture and hyperparameters for the ASL dataset\n","    - Performance of the model on the ASL dataset (at least 70% acc)\n","    - Quality of Markdown documentation\n","\n","- Submission\n","\n","Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxkzdPTx92yF"},"outputs":[],"source":["import numpy as np\n","import string\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2 as cv\n","import os\n","\n","%load_ext autoreload\n","%autoreload 2\n","#################################\n","%matplotlib inline\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"86TPdBHs92yI"},"outputs":[],"source":["# DATA_PATH = '/media/pepe/DataUbuntu/Databases/asl_data/'\n","DATA_PATH = '/home/kurtbadelt/MNA/Advanced_ML/Actividad_1b/asl_data/asl_data'\n","train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n","valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MOkNYWjs92yK","outputId":"2d6b7495-d725-4da7-da23-47ab026f37e1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>pixel1</th>\n","      <th>pixel2</th>\n","      <th>pixel3</th>\n","      <th>pixel4</th>\n","      <th>pixel5</th>\n","      <th>pixel6</th>\n","      <th>pixel7</th>\n","      <th>pixel8</th>\n","      <th>pixel9</th>\n","      <th>...</th>\n","      <th>pixel775</th>\n","      <th>pixel776</th>\n","      <th>pixel777</th>\n","      <th>pixel778</th>\n","      <th>pixel779</th>\n","      <th>pixel780</th>\n","      <th>pixel781</th>\n","      <th>pixel782</th>\n","      <th>pixel783</th>\n","      <th>pixel784</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>107</td>\n","      <td>118</td>\n","      <td>127</td>\n","      <td>134</td>\n","      <td>139</td>\n","      <td>143</td>\n","      <td>146</td>\n","      <td>150</td>\n","      <td>153</td>\n","      <td>...</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>206</td>\n","      <td>206</td>\n","      <td>206</td>\n","      <td>204</td>\n","      <td>203</td>\n","      <td>202</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6</td>\n","      <td>155</td>\n","      <td>157</td>\n","      <td>156</td>\n","      <td>156</td>\n","      <td>156</td>\n","      <td>157</td>\n","      <td>156</td>\n","      <td>158</td>\n","      <td>158</td>\n","      <td>...</td>\n","      <td>69</td>\n","      <td>149</td>\n","      <td>128</td>\n","      <td>87</td>\n","      <td>94</td>\n","      <td>163</td>\n","      <td>175</td>\n","      <td>103</td>\n","      <td>135</td>\n","      <td>149</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>187</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>187</td>\n","      <td>187</td>\n","      <td>186</td>\n","      <td>187</td>\n","      <td>188</td>\n","      <td>187</td>\n","      <td>...</td>\n","      <td>202</td>\n","      <td>201</td>\n","      <td>200</td>\n","      <td>199</td>\n","      <td>198</td>\n","      <td>199</td>\n","      <td>198</td>\n","      <td>195</td>\n","      <td>194</td>\n","      <td>195</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>211</td>\n","      <td>211</td>\n","      <td>212</td>\n","      <td>212</td>\n","      <td>211</td>\n","      <td>210</td>\n","      <td>211</td>\n","      <td>210</td>\n","      <td>210</td>\n","      <td>...</td>\n","      <td>235</td>\n","      <td>234</td>\n","      <td>233</td>\n","      <td>231</td>\n","      <td>230</td>\n","      <td>226</td>\n","      <td>225</td>\n","      <td>222</td>\n","      <td>229</td>\n","      <td>163</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12</td>\n","      <td>164</td>\n","      <td>167</td>\n","      <td>170</td>\n","      <td>172</td>\n","      <td>176</td>\n","      <td>179</td>\n","      <td>180</td>\n","      <td>184</td>\n","      <td>185</td>\n","      <td>...</td>\n","      <td>92</td>\n","      <td>105</td>\n","      <td>105</td>\n","      <td>108</td>\n","      <td>133</td>\n","      <td>163</td>\n","      <td>157</td>\n","      <td>163</td>\n","      <td>164</td>\n","      <td>179</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 785 columns</p>\n","</div>"],"text/plain":["   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n","0      3     107     118     127     134     139     143     146     150   \n","1      6     155     157     156     156     156     157     156     158   \n","2      2     187     188     188     187     187     186     187     188   \n","3      2     211     211     212     212     211     210     211     210   \n","4     12     164     167     170     172     176     179     180     184   \n","\n","   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n","0     153  ...       207       207       207       207       206       206   \n","1     158  ...        69       149       128        87        94       163   \n","2     187  ...       202       201       200       199       198       199   \n","3     210  ...       235       234       233       231       230       226   \n","4     185  ...        92       105       105       108       133       163   \n","\n","   pixel781  pixel782  pixel783  pixel784  \n","0       206       204       203       202  \n","1       175       103       135       149  \n","2       198       195       194       195  \n","3       225       222       229       163  \n","4       157       163       164       179  \n","\n","[5 rows x 785 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"zyMCbZMy92yN"},"source":["### Importar Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fNKS-3Cr92yO"},"outputs":[],"source":["y_train = np.array(train_df['label'])\n","y_val = np.array(valid_df['label'])\n","del train_df['label']\n","del valid_df['label']\n","x_train = train_df.values.astype(np.float32)\n","x_val = valid_df.values.astype(np.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kUL9kO1-92yP","outputId":"4d3c00a4-4be5-4efe-f2e3-8d9b142a7506"},"outputs":[{"name":"stdout","output_type":"stream","text":["x_train shape: (27455, 784)\n","y_train shape: (27455,)\n"]}],"source":["print(\"x_train shape:\", x_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OireedIC92yS","outputId":"d14c1c8c-8a07-4ec6-8266-1793a4f50ec0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[107. 118. 127. ... 204. 203. 202.]\n"," [155. 157. 156. ... 103. 135. 149.]\n"," [187. 188. 188. ... 195. 194. 195.]\n"," [211. 211. 212. ... 222. 229. 163.]\n"," [164. 167. 170. ... 163. 164. 179.]]\n","[ 3  6  2  2 12]\n"]}],"source":["# print the firist 5 rows of the x_train and y_train\n","print(x_train[:5])\n","print(y_train[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"code_folding":[],"id":"MWGcm-BT92yT"},"outputs":[],"source":["\n","\n","def split_val_test(x, y, pct=0.5, shuffle=True):\n","    '''\n","    Splits the dataset into validation and test sets based on the given percentage.\n","\n","    Parameters:\n","    - x (numpy.ndarray): Feature data.\n","    - y (numpy.ndarray): Labels corresponding to the feature data.\n","    - pct (float): Proportion of the data to include in the validation set (between 0 and 1).\n","    - shuffle (bool): Whether to shuffle the data before splitting.\n","\n","    Returns:\n","    - x_val (numpy.ndarray): Validation feature data.\n","    - y_val (numpy.ndarray): Validation labels.\n","    - x_test (numpy.ndarray): Test feature data.\n","    - y_test (numpy.ndarray): Test labels.\n","    '''\n","    # Ensure x and y have the same number of samples\n","    assert x.shape[0] == y.shape[0], \"The number of samples in x and y must be equal.\"\n","\n","    num_samples = x.shape[0]\n","    indices = np.arange(num_samples)\n","\n","    if shuffle:\n","        np.random.shuffle(indices)\n","\n","    # Calculate the number of samples for the validation set\n","    num_val_samples = int(np.floor(num_samples * pct))\n","\n","    # Split indices for validation and test sets\n","    val_indices = indices[:num_val_samples]\n","    test_indices = indices[num_val_samples:]\n","\n","    # Create validation and test sets\n","    x_val = x[val_indices]\n","    y_val = y[val_indices]\n","    x_test = x[test_indices]\n","    y_test = y[test_indices]\n","\n","    return x_val, y_val, x_test, y_test\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wo0bji8T92yU"},"outputs":[],"source":["x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FsBhi_gX92yV","outputId":"586ff024-9e98-403e-ce2c-0d6f94f9bb0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["24\n","['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y']\n"]}],"source":["### The following\n","\n","alphabet=list(string.ascii_lowercase)\n","alphabet.remove('j')\n","alphabet.remove('z')\n","print(len(alphabet))\n","print(alphabet)"]},{"cell_type":"markdown","metadata":{"id":"t-8wgtSO92yV"},"source":["### Normalise"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uqxE1kQd92yW"},"outputs":[],"source":["def normalise(x_mean, x_std, x_data):\n","    x_std_adj = np.where(x_std == 0, 1e-8, x_std)\n","    return (x_data - x_mean) / x_std_adj\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3OxFgJPh92yW"},"outputs":[],"source":["x_mean = x_train.mean()\n","x_std = x_train.std()\n","\n","x_train = normalise(x_mean, x_std, x_train)\n","x_val = normalise(x_mean, x_std, x_val)\n","x_test = normalise(x_mean, x_std, x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qx2uuNPp92yX","outputId":"1c279bbd-00ff-47d6-8d19-14f97da01b03"},"outputs":[{"data":{"text/plain":["(np.float32(3.6268384e-06), np.float32(0.99999946))"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["x_train.mean(), x_train.std()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOqw7I2j92yX"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Hgt_kVYp92yY"},"source":["### Graficar muestras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fQhzUQO92yY","outputId":"81d54586-a86c-4074-9bef-84a7e366afd6"},"outputs":[{"name":"stdout","output_type":"stream","text":["x_train shape: (27455, 784)\n","y_train shape: (27455,)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Actual letter: n\n"]}],"source":["\n","\n","print(\"x_train shape:\", x_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","\n","\n","\n","# Plot the image\n","def plot_image(image):\n","    plt.imshow(image, cmap='gray')\n","    plt.axis('off')\n","    plt.show()\n","idx = np.random.randint(len(y_test))\n","actual_index = y_test[idx]\n","plot_image(x_test[idx].reshape(28, 28))\n","print(f\"Actual letter: {alphabet[actual_index]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgsV7AG992yZ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dp2pYfPb92yZ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"LKYLeYX192yZ"},"source":["### Ecuaciones para nuestro modelo\n","\n","\n","$$z^1 = W^1 X + b^1$$\n","\n","$$a^1 = ReLU(z^1) $$\n","\n","$$z^2 = W^2 a^1 + b^2$$\n","\n","$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n","\n","\n","$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n","\n","\n","$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"]},{"cell_type":"markdown","metadata":{"id":"FdAFeWcr92yZ"},"source":["### Funciones adicionales"]},{"cell_type":"markdown","metadata":{"id":"mxEa632M92ya"},"source":["#### Mini batches"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HwzkPf1Y92ya"},"outputs":[],"source":["def create_minibatches(mb_size, x, y, shuffle = True):\n","    '''\n","    x  #muestras, 784\n","    y #muestras, 1\n","    '''\n","    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n","    total_data = x.shape[0]\n","    if shuffle:\n","        idxs = np.arange(total_data)\n","        np.random.shuffle(idxs)\n","        x = x[idxs]\n","        y = y[idxs]\n","    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DTKyPi9H92ya"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pm4DGHqM92ya"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"BCE9bAh692ya"},"source":["## Nuestra clase Linear, ReLU y Sequential"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rNhN9q9m92ya"},"outputs":[],"source":["class Tensor:\n","    \"\"\"\n","    Class to represent a tensor object.\n","    in this case, the tensor is a numpy array\n","    inherited from the numpy array class\n","    and has an additional attribute to store the gradient\n","    \"\"\"\n","    def __init__(self, data):\n","        self.data = data  # numpy array\n","        self.grad = np.zeros_like(data)\n"]},{"cell_type":"markdown","metadata":{"id":"v2wDFCo192yb"},"source":["###  Clase Linear"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RmaCO1vj92yb"},"outputs":[],"source":["class Linear:\n","    \"\"\"\n","    Class to represent a linear layer.\n","    represents a linear transformation of the form y = Wx + b\n","    \"\"\"\n","    def __init__(self, input_size, output_size):\n","        std_dev = np.sqrt(2.0 / input_size)\n","        self.W = Tensor(np.random.randn(output_size, input_size) * std_dev)\n","        self.b = Tensor(np.zeros((output_size, 1)))\n","\n","    def forward(self, X): #antes __call__ cambiÃ© por forward para que sea mÃ¡s claro\n","        \"\"\"\n","        Performs the forward pass.\n","        z_i = W_i * x + b_i\n","        Parameters:\n","        - X (np.ndarray): Input data.\n","        \"\"\"\n","        self.input = X.data  # Store as NumPy array\n","        Z_data = self.W.data @ self.input + self.b.data # Compute linear transformation\n","        return Tensor(Z_data) # Return as Tensor object\n","\n","    def backward(self, grad_output):\n","        \"\"\"\n","        Performs the backward pass.\n","\n","        Parameters:\n","        - grad_output (np.ndarray): Gradient of the loss with respect to the output Z.\n","\n","        Returns:\n","        - grad_input (np.ndarray): Gradient with respect to the input X.\n","        grad_output = dL/dZ\n","        \"\"\"\n","        # Update gradients of parameters\n","        self.W.grad += grad_output @ self.input.T\n","        self.b.grad += np.sum(grad_output, axis=1, keepdims=True)\n","        # Compute gradient with respect to input\n","        grad_input = self.W.data.T @ grad_output # dL/dX = W^T * dL/dZ\n","        return grad_input  # Return as NumPy array\n","\n","\n",""]},{"cell_type":"markdown","metadata":{"id":"1f2NkAtF92yc"},"source":["### Clase ReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iBejfRxy92yc"},"outputs":[],"source":["class ReLU:\n","    \"\"\"\n","    Class to represent a ReLU activation function.\n","    ReLU activation function is defined as f(x) = max(0, x).\n","    \"\"\"\n","    def forward(self, X):\n","        \"\"\"\n","        Forward pass for ReLU activation.\n","        \"\"\"\n","        self.input = X\n","        A_data = np.maximum(0, X.data)\n","        A = Tensor(A_data)\n","        return A\n","\n","    def backward(self, grad_output):\n","        \"\"\"\n","        Backward pass for ReLU activation.\n","\n","        Parameters:\n","        - grad_output (np.ndarray): Gradient of the loss with respect to the output of ReLU.\n","\n","        Returns:\n","        - grad_input (np.ndarray): Gradient with respect to the input Z.\n","        \"\"\"\n","        grad_input = grad_output * (self.input.data > 0)\n","        return grad_input  # Return as NumPy array"]},{"cell_type":"markdown","metadata":{"id":"ew2jm2zp92yd"},"source":["### Clase Sequential"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bcB2P58b92yd"},"outputs":[],"source":["def softmax(Z):\n","    \"\"\"\n","    Applies the softmax function to the input array.\n","    implemented to avoid overflow and underflow errors.\n","    defined as f_i(z) = e^z_i / sum(e^z)\n","\n","    Parameters:\n","    - Z (np.ndarray): Input array.\n","\n","    Returns:\n","    - np.ndarray: Softmax probabilities.\n","    \"\"\"\n","    exp_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True)) # Subtract max to avoid overflow\n","    return exp_Z / np.sum(exp_Z, axis=0, keepdims=True) # Compute softmax probabilities\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QYeQpTKB92ye"},"outputs":[],"source":["class Sequential:\n","    \"\"\"\n","    Class to represent a sequential neural network model.\n","    defined as a sequence of layers.\n","    \"\"\"\n","    def __init__(self, layers):\n","        \"\"\"\n","        Constructor for the Sequential class.\n","        Parameters:\n","        - layers (list): List of layers in the network.\n","        \"\"\"\n","        self.layers = layers\n","\n","    def forward(self, X):\n","        \"\"\"A1b_DL_TC5033.ipynb\n","        performs the forward pass through the network.\n","        Parameters:\n","        - X (np.ndarray): Input data.\n","        returns the output of the network.\n","        \"\"\"\n","        for layer in self.layers:\n","            X = layer.forward(X) # Forward pass through layer\n","        return X\n","\n","    def backward(self, loss_grad):\n","        \"\"\"\n","        performs the backward pass through the network.\n","        Parameters:\n","        - loss_grad (np.ndarray): Gradient of the loss with respect to the output of the network.\n","        \"\"\"\n","\n","        grad = loss_grad\n","        for layer in reversed(self.layers):\n","            grad = layer.backward(grad) # Backward pass through layer\n","\n","    def zero_grad(self):\n","        \"\"\"\n","        Resets the gradients of the parameters in the network.\n","        \"\"\"\n","        for layer in self.layers:\n","            if hasattr(layer, 'W'):\n","                layer.W.grad.fill(0)\n","                layer.b.grad.fill(0)\n","\n","    def update_parameters(self, learning_rate):\n","        \"\"\"\n","        Updates the parameters of the network using gradient descent.\n","        Parameters:\n","        - learning_rate (float): Learning rate for the update.\n","\n","        \"\"\"\n","        for layer in self.layers:\n","            if hasattr(layer, 'W'): # Check if layer has weights\n","                layer.W.data -= learning_rate * layer.W.grad # Update weights\n","                layer.b.data -= learning_rate * layer.b.grad # Update biases\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Predicts the output of the network for the given input.\n","        Parameters:\n","        - X (np.ndarray): Input data.\n","        Returns:\n","        - np.ndarray: Predicted labels.\n","        \"\"\"\n","        output = self.forward(X) # Forward pass\n","        probabilities = softmax(output.data) # Compute softmax probabilities\n","        predictions = np.argmax(probabilities, axis=0) # Get predicted labels\n","        return predictions\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OwIop6Q392ye"},"source":["### Cost Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O4TUahrl92yf"},"outputs":[],"source":["def cross_entropy_loss(outputs, labels):\n","    \"\"\"\n","    Computes the cross-entropy loss and its gradient.\n","\n","    Parameters:\n","    - outputs (Tensor): Output tensor from the model (logits).\n","    - labels (np.ndarray): True labels.\n","\n","    Returns:\n","    - loss (float): The loss value.\n","    - grad (np.ndarray): Gradient of the loss with respect to outputs.\n","    \"\"\"\n","    m = labels.shape[0]\n","    probabilities = softmax(outputs.data)\n","    # Convert labels to one-hot encoding\n","    one_hot_labels = np.zeros_like(probabilities)\n","    one_hot_labels[labels, np.arange(m)] = 1\n","    loss = -np.sum(one_hot_labels * np.log(probabilities + 1e-15)) / m # Compute cross-entropy loss with small epsilon\n","    grad = (probabilities - one_hot_labels) / m # Compute gradient of the loss\n","    return loss, grad\n"]},{"cell_type":"markdown","metadata":{"id":"IZBFiH5o92yf"},"source":["### Loop de entrenamiento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-1-_w7R92yf"},"outputs":[],"source":["def train(model, epochs, mb_size=128, learning_rate=1e-3):\n","    \"\"\"\n","    Trains the model using mini-batch gradient descent.\n","    Parameters:\n","    - model (Sequential): Neural network model.\n","    - epochs (int): Number of training epochs.\n","    - mb_size (int): Mini-batch size.\n","    - learning_rate (float): Learning rate for gradient descent.\n","    \"\"\"\n","\n","    for epoch in range(epochs):\n","        for x_batch, y_batch in create_minibatches(mb_size, x_train, y_train):\n","            inputs = Tensor(x_batch.T)  # Input tensor\n","            outputs = model.forward(inputs)\n","            loss, grad = cross_entropy_loss(outputs.data, y_batch)\n","            model.zero_grad()\n","            model.backward(grad)  # grad is a NumPy array\n","            model.update_parameters(learning_rate)\n","        # Optionally, compute accuracy on validation set\n","        val_accuracy = calculate_accuracy(model, x_val, y_val)\n","        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3QD_NTOr92yp"},"outputs":[],"source":["def calculate_accuracy(model, x_data, y_data):\n","    \"\"\"\n","    Calculates the accuracy of the model on the given data.\n","    Parameters:\n","    - model (Sequential): Neural network model.\n","    - x_data (np.ndarray): Input data.\n","    - y_data (np.ndarray): True labels.\n","    Returns:\n","    - float: Accuracy of the model on the data.\n","    \"\"\"\n","    mb_size = 128\n","    correct = 0\n","    total = 0\n","    for x_batch, y_batch in create_minibatches(mb_size, x_data, y_data):\n","        inputs = Tensor(x_batch.T)\n","        predictions = model.predict(inputs)\n","        correct += np.sum(predictions == y_batch)\n","        total += y_batch.shape[0]\n","    return correct / total\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RVF9Ru5W92yq"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ZLCzN19j92yq"},"source":["### Create your model and train it"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q9UOJcMJ92yq"},"outputs":[],"source":["\"\"\"\n","model = Sequential([\n","    Linear(784, 200),\n","    ReLU(),\n","    Linear(200, 200),\n","    ReLU(),\n","    Linear(200, 24)  # Adjusted output size to match 24 classes\n","])\n","\"\"\"\n","#Testing with a more complex architecture\n","#adding hidden layers, that reduce the number of neurons in each layer to force the model to learn more abstract features\n","model = Sequential([\n","    Linear(784, 512),\n","    ReLU(),\n","    Linear(512, 256),\n","    ReLU(),\n","    Linear(256, 128),\n","    ReLU(),\n","    Linear(128, 64),\n","    ReLU(),\n","    Linear(64, 24)\n","])\n","\n","\n","\n","mb_size = 128 # Mini-batch size\n","learning_rate = 1e-3 # Learning rate\n","epochs = 100  # Number of training epochs, this impacted the accuracy of the model allowing us to reach a 75% accuracy\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"azB3pYkM92yr","outputId":"f6af68eb-c34d-4d6f-c961-7e803172ce94"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100, Loss: 3.0898, Validation Accuracy: 0.1294\n","Epoch 2/100, Loss: 2.7913, Validation Accuracy: 0.1893\n","Epoch 3/100, Loss: 2.3828, Validation Accuracy: 0.2521\n","Epoch 4/100, Loss: 1.9955, Validation Accuracy: 0.2992\n","Epoch 5/100, Loss: 1.8825, Validation Accuracy: 0.3419\n","Epoch 6/100, Loss: 1.8830, Validation Accuracy: 0.3951\n","Epoch 7/100, Loss: 1.6439, Validation Accuracy: 0.4286\n","Epoch 8/100, Loss: 1.3490, Validation Accuracy: 0.4688\n","Epoch 9/100, Loss: 1.1675, Validation Accuracy: 0.4972\n","Epoch 10/100, Loss: 1.0435, Validation Accuracy: 0.5162\n","Epoch 11/100, Loss: 0.8376, Validation Accuracy: 0.5301\n","Epoch 12/100, Loss: 1.0584, Validation Accuracy: 0.5452\n","Epoch 13/100, Loss: 0.8288, Validation Accuracy: 0.5547\n","Epoch 14/100, Loss: 0.5817, Validation Accuracy: 0.5764\n","Epoch 15/100, Loss: 0.6492, Validation Accuracy: 0.5904\n","Epoch 16/100, Loss: 0.5393, Validation Accuracy: 0.6032\n","Epoch 17/100, Loss: 0.5463, Validation Accuracy: 0.6107\n","Epoch 18/100, Loss: 0.5115, Validation Accuracy: 0.6233\n","Epoch 19/100, Loss: 0.4084, Validation Accuracy: 0.6319\n","Epoch 20/100, Loss: 0.4741, Validation Accuracy: 0.6403\n","Epoch 21/100, Loss: 0.4239, Validation Accuracy: 0.6509\n","Epoch 22/100, Loss: 0.3532, Validation Accuracy: 0.6545\n","Epoch 23/100, Loss: 0.4490, Validation Accuracy: 0.6615\n","Epoch 24/100, Loss: 0.3188, Validation Accuracy: 0.6712\n","Epoch 25/100, Loss: 0.2325, Validation Accuracy: 0.6740\n","Epoch 26/100, Loss: 0.2509, Validation Accuracy: 0.6804\n","Epoch 27/100, Loss: 0.3298, Validation Accuracy: 0.6854\n","Epoch 28/100, Loss: 0.1794, Validation Accuracy: 0.6896\n","Epoch 29/100, Loss: 0.2299, Validation Accuracy: 0.6921\n","Epoch 30/100, Loss: 0.1595, Validation Accuracy: 0.6952\n","Epoch 31/100, Loss: 0.2067, Validation Accuracy: 0.6997\n","Epoch 32/100, Loss: 0.1278, Validation Accuracy: 0.7013\n","Epoch 33/100, Loss: 0.1222, Validation Accuracy: 0.7013\n","Epoch 34/100, Loss: 0.1481, Validation Accuracy: 0.7066\n","Epoch 35/100, Loss: 0.1082, Validation Accuracy: 0.7041\n","Epoch 36/100, Loss: 0.1348, Validation Accuracy: 0.7072\n","Epoch 37/100, Loss: 0.1238, Validation Accuracy: 0.7086\n","Epoch 38/100, Loss: 0.1290, Validation Accuracy: 0.7089\n","Epoch 39/100, Loss: 0.1293, Validation Accuracy: 0.7142\n","Epoch 40/100, Loss: 0.0954, Validation Accuracy: 0.7128\n","Epoch 41/100, Loss: 0.1269, Validation Accuracy: 0.7153\n","Epoch 42/100, Loss: 0.1251, Validation Accuracy: 0.7153\n","Epoch 43/100, Loss: 0.1197, Validation Accuracy: 0.7158\n","Epoch 44/100, Loss: 0.1170, Validation Accuracy: 0.7183\n","Epoch 45/100, Loss: 0.0569, Validation Accuracy: 0.7170\n","Epoch 46/100, Loss: 0.0894, Validation Accuracy: 0.7192\n","Epoch 47/100, Loss: 0.0573, Validation Accuracy: 0.7206\n","Epoch 48/100, Loss: 0.0580, Validation Accuracy: 0.7220\n","Epoch 49/100, Loss: 0.0758, Validation Accuracy: 0.7225\n","Epoch 50/100, Loss: 0.0961, Validation Accuracy: 0.7239\n","Epoch 51/100, Loss: 0.0490, Validation Accuracy: 0.7242\n","Epoch 52/100, Loss: 0.0778, Validation Accuracy: 0.7253\n","Epoch 53/100, Loss: 0.0502, Validation Accuracy: 0.7270\n","Epoch 54/100, Loss: 0.0503, Validation Accuracy: 0.7309\n","Epoch 55/100, Loss: 0.0617, Validation Accuracy: 0.7287\n","Epoch 56/100, Loss: 0.0833, Validation Accuracy: 0.7284\n","Epoch 57/100, Loss: 0.0639, Validation Accuracy: 0.7270\n","Epoch 58/100, Loss: 0.0482, Validation Accuracy: 0.7298\n","Epoch 59/100, Loss: 0.0325, Validation Accuracy: 0.7289\n","Epoch 60/100, Loss: 0.0584, Validation Accuracy: 0.7331\n","Epoch 61/100, Loss: 0.0320, Validation Accuracy: 0.7326\n","Epoch 62/100, Loss: 0.0257, Validation Accuracy: 0.7331\n","Epoch 63/100, Loss: 0.0454, Validation Accuracy: 0.7337\n","Epoch 64/100, Loss: 0.0478, Validation Accuracy: 0.7348\n","Epoch 65/100, Loss: 0.0249, Validation Accuracy: 0.7345\n","Epoch 66/100, Loss: 0.0375, Validation Accuracy: 0.7345\n","Epoch 67/100, Loss: 0.0276, Validation Accuracy: 0.7368\n","Epoch 68/100, Loss: 0.0336, Validation Accuracy: 0.7365\n","Epoch 69/100, Loss: 0.0402, Validation Accuracy: 0.7379\n","Epoch 70/100, Loss: 0.0345, Validation Accuracy: 0.7368\n","Epoch 71/100, Loss: 0.0243, Validation Accuracy: 0.7379\n","Epoch 72/100, Loss: 0.0362, Validation Accuracy: 0.7376\n","Epoch 73/100, Loss: 0.0193, Validation Accuracy: 0.7384\n","Epoch 74/100, Loss: 0.0345, Validation Accuracy: 0.7384\n","Epoch 75/100, Loss: 0.0309, Validation Accuracy: 0.7390\n","Epoch 76/100, Loss: 0.0303, Validation Accuracy: 0.7395\n","Epoch 77/100, Loss: 0.0286, Validation Accuracy: 0.7401\n","Epoch 78/100, Loss: 0.0379, Validation Accuracy: 0.7418\n","Epoch 79/100, Loss: 0.0240, Validation Accuracy: 0.7412\n","Epoch 80/100, Loss: 0.0297, Validation Accuracy: 0.7415\n","Epoch 81/100, Loss: 0.0328, Validation Accuracy: 0.7418\n","Epoch 82/100, Loss: 0.0242, Validation Accuracy: 0.7426\n","Epoch 83/100, Loss: 0.0193, Validation Accuracy: 0.7429\n","Epoch 84/100, Loss: 0.0127, Validation Accuracy: 0.7426\n","Epoch 85/100, Loss: 0.0207, Validation Accuracy: 0.7429\n","Epoch 86/100, Loss: 0.0209, Validation Accuracy: 0.7434\n","Epoch 87/100, Loss: 0.0249, Validation Accuracy: 0.7429\n","Epoch 88/100, Loss: 0.0271, Validation Accuracy: 0.7446\n","Epoch 89/100, Loss: 0.0164, Validation Accuracy: 0.7451\n","Epoch 90/100, Loss: 0.0189, Validation Accuracy: 0.7446\n","Epoch 91/100, Loss: 0.0129, Validation Accuracy: 0.7454\n","Epoch 92/100, Loss: 0.0195, Validation Accuracy: 0.7460\n","Epoch 93/100, Loss: 0.0148, Validation Accuracy: 0.7457\n","Epoch 94/100, Loss: 0.0173, Validation Accuracy: 0.7460\n","Epoch 95/100, Loss: 0.0206, Validation Accuracy: 0.7468\n","Epoch 96/100, Loss: 0.0259, Validation Accuracy: 0.7462\n","Epoch 97/100, Loss: 0.0163, Validation Accuracy: 0.7468\n","Epoch 98/100, Loss: 0.0166, Validation Accuracy: 0.7460\n","Epoch 99/100, Loss: 0.0186, Validation Accuracy: 0.7462\n","Epoch 100/100, Loss: 0.0164, Validation Accuracy: 0.7460\n"]}],"source":["train(model, epochs, mb_size, learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YIjHu7Ik92yr"},"outputs":[],"source":["\n"]},{"cell_type":"markdown","metadata":{"id":"xQPMHpoI92ys"},"source":["### Test your model on Random data from your test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oyu5xrep92ys","outputId":"4bc32ef3-7abb-4a47-c93f-dd58c018bbd6"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["The predicted value is: w, the real value is: w\n"]}],"source":["# Select a random index from the test set\n","idx = np.random.randint(len(y_test))\n","\n","# Plot the image\n","def plot_image(image):\n","    plt.imshow(image, cmap='gray')\n","    plt.axis('off')\n","    plt.show()\n","\n","plot_image(x_test[idx].reshape(28, 28))\n","\n","# Prepare the input tensor for prediction\n","input_sample = x_test[idx].reshape(-1, 1)  # Shape: (784, 1)\n","input_tensor = Tensor(input_sample)\n","\n","# Make a prediction\n","pred = model.predict(input_tensor)\n","\n","# Extract the predicted and actual indices\n","predicted_index = pred[0]\n","actual_index = y_test[idx]\n","\n","# Map indices to letters\n","predicted_letter = alphabet[predicted_index]\n","actual_letter = alphabet[actual_index]\n","\n","print(f'The predicted value is: {predicted_letter}, the real value is: {actual_letter}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NOUe5Zm192yt"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wwa37BQw92yu"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}